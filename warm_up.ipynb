{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","import torch \n","from transformers import AutoModelForSeq2SeqLM, AutoModelForCausalLM, AutoTokenizer, pipeline , GenerationConfig, TrainingArguments, Trainer\n","import torch\n","import time\n","import evaluate\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","data = pd.read_csv(\"/kaggle/input/llm1234/train.csv\")\n","train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.random.manual_seed(0) \n","model = AutoModelForCausalLM.from_pretrained( \n","    \"microsoft/Phi-3-mini-4k-instruct\",  \n","    device_map=\"cuda\",  \n","    torch_dtype=\"auto\",  \n","    trust_remote_code=True,  \n",") \n","\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\") "]},{"cell_type":"markdown","metadata":{},"source":["# Metric"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MAP@3: 0.8333333333333334\n"]}],"source":["def mapk(actual, predicted, k=3):\n","    \"\"\"\n","    Computes the mean average precision at k (MAP@k).\n","    \n","    Parameters:\n","    actual : list\n","        A list of correct labels, where each entry corresponds to the correct label for a single question.\n","    predicted : list\n","        A list of lists. Each inner list contains the predicted labels for a single question.\n","    k : int, optional (default=3)\n","        The maximum number of predicted elements to consider.\n","        \n","    Returns:\n","    score : float\n","        The MAP@k score for the predictions.\n","    \"\"\"\n","    def apk(actual, predicted, k=3):\n","        \"\"\"\n","        Computes the average precision at k (AP@k) for a single observation.\n","        \"\"\"\n","        if len(predicted) > k:\n","            predicted = predicted[:k]\n","        \n","        for i, p in enumerate(predicted):\n","            if p == actual:\n","                return 1.0 / (i + 1.0)\n","        \n","        return 0.0\n","    \n","    return sum(apk(a, p, k) for a, p in zip(actual, predicted)) / len(actual)\n","\n","# Example usage\n","actual = ['A', 'B', 'C']\n","predicted = [['A', 'B', 'C'], ['D', 'B', 'C'], ['C', 'A', 'B']]\n","score = mapk(actual, predicted, k=3)\n","print(f'MAP@3: {score}')"]},{"cell_type":"markdown","metadata":{},"source":["# Zero shot inferencing "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["index = 0\n","\n","question = train_df.iloc[index]['prompt']\n","A = train_df.iloc[index]['A']\n","B = train_df.iloc[index]['B']\n","C = train_df.iloc[index]['C']\n","D = train_df.iloc[index]['D']\n","E = train_df.iloc[index]['E']\n","answer = train_df.iloc[index]['answer']\n","\n","\n","\n","\n","example = f\"\"\"\n","Choose the correct answer for this question. To answer this question, let's analyze each option step by step \n","\n","Question : What is the capital of france\n","A : Lyon\n","B : Paris\n","C : London\n","D : Toulouse\n","E : Madrid\n","\n","\"\"\"\n","\n","prompt = f\"\"\"\n","Choose the correct answer for this question. To answer this question, let's analyze each option step by step \n","\n","Question : {question}\n","A : {A}\n","B : {B}\n","C : {C}\n","D : {D}\n","E : {E}\n","\n","\"\"\"\n","\n","\n","\n","messages = [ \n","    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant for question answering.\"}, \n","    {\"role\": \"user\", \"content\": f\"{example}\"}, \n","    {\"role\": \"assistant\", \"content\": \"B\"}, \n","    {\"role\": \"user\", \"content\": f\"{prompt}\"}, \n","] \n","\n","pipe = pipeline( \n","    \"text-generation\", \n","    model=model, \n","    tokenizer=tokenizer, \n",") \n","\n","generation_args = { \n","    \"max_new_tokens\": 500, \n","    \"return_full_text\": False, \n","    \"temperature\": 0.0, \n","    \"do_sample\": False, \n","} \n","\n","output = pipe(messages, **generation_args) \n","responce = output[0]['generated_text'] \n","\n","dash_line = '-'.join('' for x in range(100))\n","print(dash_line)\n","print(f'INPUT PROMPT:\\n{prompt}')\n","print(dash_line)\n","print(f'Correct Answer:\\n{answer}\\n')\n","print(dash_line)\n","print(f'MODEL Prediction - ZERO SHOT:\\n{responce}')"]},{"cell_type":"markdown","metadata":{},"source":["---------------------------------------------------------------------------------------------------\n","INPUT PROMPT:\n","\n","Choose the correct answer for this question. To answer this question, let's analyze each option step by step \n","\n","Question : What is a Hilbert space in quantum mechanics?\n","A : A complex vector space where the state of a classical mechanical system is described by a vector |Ψ⟩.\n","B : A physical space where the state of a classical mechanical system is described by a vector |Ψ⟩.\n","C : A physical space where the state of a quantum mechanical system is described by a vector |Ψ⟩.\n","D : A mathematical space where the state of a classical mechanical system is described by a vector |Ψ⟩.\n","E : A complex vector space where the state of a quantum mechanical system is described by a vector |Ψ⟩.\n","\n","\n","---------------------------------------------------------------------------------------------------\n","Correct Answer:\n","\n","E\n","\n","---------------------------------------------------------------------------------------------------\n","MODEL Prediction - ZERO SHOT:\n","\n"," E"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize lists to hold actual and predicted values\n","actual_labels = []\n","predicted_labels = []\n","\n","pipe = pipeline( \n","        \"text-generation\", \n","        model=model, \n","        tokenizer=tokenizer, \n","    ) \n","\n","generation_args = { \n","    \"max_new_tokens\": 500, \n","    \"return_full_text\": False, \n","    \"temperature\": 0.0, \n","    \"do_sample\": False, \n","} \n","\n","for index, row in test_df.iterrows():\n","    question = row['prompt']\n","    A = row['A']\n","    B = row['B']\n","    C = row['C']\n","    D = row['D']\n","    E = row['E']\n","    answer = row['answer']\n","    \n","    # Add the correct answer to the actual labels list\n","    actual_labels.append(answer)\n","    \n","    prompt = f\"\"\"\n","    Choose the correct answer for this question. To answer this question, let's analyze each option step by step \n","\n","    Question : {question}\n","    A : {A}\n","    B : {B}\n","    C : {C}\n","    D : {D}\n","    E : {E}\n","\n","    \"\"\"\n","    \n","    # Construct the prompt\n","    messages = [ \n","    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant for question answering.\"}, \n","    {\"role\": \"user\", \"content\": f\"{example}\"}, \n","    {\"role\": \"assistant\", \"content\": \"B\"}, \n","    {\"role\": \"user\", \"content\": f\"{prompt}\"}, \n","    ] \n","\n","    output = pipe(messages, **generation_args) \n","    responce = output[0]['generated_text'] \n","    \n","    # Convert the output to a list and add it to the predicted labels list\n","    predicted_labels.append([responce.strip()])\n","    \n","# Calculate the MAP@k\n","k = 3  # You can change k if needed\n","mapk_score = mapk(actual_labels, predicted_labels, k)\n","print(f'MAP@{k} with the original model - Zero Shot: {mapk_score}')"]},{"cell_type":"markdown","metadata":{},"source":["MAP@3 with the original model - Zero Shot: 0.775\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":6169864,"sourceId":54662,"sourceType":"competition"},{"datasetId":3705022,"sourceId":6422564,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
